{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will working with some California Census Data .We will be trying to use various \n",
    "features of an individuals to predict the what class of income they belong in (>50k or <=50k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the census_data.csv data with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "census=pd.read_csv('census_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>work_class</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>fifty_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>Private</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Amer-Indian-Eskimo</td>\n",
       "      <td>Female</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Amer-Indian-Eskimo</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>Private</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Amer-Indian-Eskimo</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Amer-Indian-Eskimo</td>\n",
       "      <td>Male</td>\n",
       "      <td>75</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age work_class education  education_num marital_status         occupation  \\\n",
       "0   47    Private      10th              6       Divorced    Exec-managerial   \n",
       "1   40    Private      10th              6       Divorced       Craft-repair   \n",
       "2   30    Private      10th              6       Divorced      Other-service   \n",
       "3   27    Private      10th              6       Divorced   Transport-moving   \n",
       "4   38    Private      10th              6       Divorced  Machine-op-inspct   \n",
       "\n",
       "    relationship                race     sex  hours_per_week native_country  \\\n",
       "0  Not-in-family  Amer-Indian-Eskimo  Female              45  United-States   \n",
       "1  Not-in-family  Amer-Indian-Eskimo    Male              40  United-States   \n",
       "2  Not-in-family  Amer-Indian-Eskimo    Male              40  United-States   \n",
       "3  Not-in-family  Amer-Indian-Eskimo    Male              75  United-States   \n",
       "4  Not-in-family  Asian-Pac-Islander  Female              40       Portugal   \n",
       "\n",
       "  fifty_k  \n",
       "0   <=50K  \n",
       "1   <=50K  \n",
       "2   <=50K  \n",
       "3   <=50K  \n",
       "4   <=50K  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow won't not understand String as labels,you will need to use pandas .apply() method to apply\n",
    "a custom function that converts them to 0s and 1s. this might be hard if you are't very familier with pandas so feel free to take a peek at the the solutions for this part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the Labels columns to 0's and 1s instead of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<=50K', '>50K'], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census['fifty_k'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_fix(label):\n",
    "    if label =='<=50k':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "census['fifty_k']=census['fifty_k'].apply(label_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>work_class</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>fifty_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>Private</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Amer-Indian-Eskimo</td>\n",
       "      <td>Female</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Amer-Indian-Eskimo</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>Private</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Amer-Indian-Eskimo</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Amer-Indian-Eskimo</td>\n",
       "      <td>Male</td>\n",
       "      <td>75</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age work_class education  education_num marital_status         occupation  \\\n",
       "0   47    Private      10th              6       Divorced    Exec-managerial   \n",
       "1   40    Private      10th              6       Divorced       Craft-repair   \n",
       "2   30    Private      10th              6       Divorced      Other-service   \n",
       "3   27    Private      10th              6       Divorced   Transport-moving   \n",
       "4   38    Private      10th              6       Divorced  Machine-op-inspct   \n",
       "\n",
       "    relationship                race     sex  hours_per_week native_country  \\\n",
       "0  Not-in-family  Amer-Indian-Eskimo  Female              45  United-States   \n",
       "1  Not-in-family  Amer-Indian-Eskimo    Male              40  United-States   \n",
       "2  Not-in-family  Amer-Indian-Eskimo    Male              40  United-States   \n",
       "3  Not-in-family  Amer-Indian-Eskimo    Male              75  United-States   \n",
       "4  Not-in-family  Asian-Pac-Islander  Female              40       Portugal   \n",
       "\n",
       "   fifty_k  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a Train Test Split on the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data=census.drop('fifty_k',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels=census['fifty_k']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x_data,y_labels,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create  the feature columns for tf.estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take note of categorical vs continious values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'work_class', 'education', 'education_num', 'marital_status',\n",
       "       'occupation', 'relationship', 'race', 'sex', 'hours_per_week',\n",
       "       'native_country', 'fifty_k'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create the tf.feature_column for categorical values use vocabulary lists or just use hash bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gender=tf.feature_column.categorical_column_with_vocabulary_list('sex',['Female','Male'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation=tf.feature_column.categorical_column_with_hash_bucket('occupation',hash_bucket_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrial_status=tf.feature_column.categorical_column_with_hash_bucket('marital_status',hash_bucket_size=1000)\n",
    "relationship=tf.feature_column.categorical_column_with_hash_bucket('relationship',hash_bucket_size=1000)\n",
    "education=tf.feature_column.categorical_column_with_hash_bucket('education',hash_bucket_size=1000)\n",
    "workclass=tf.feature_column.categorical_column_with_hash_bucket('work_class',hash_bucket_size=1000)\n",
    "native_country=tf.feature_column.categorical_column_with_hash_bucket('native_country',hash_bucket_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the continious features_columns for the continious values using numeric_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "age=tf.feature_column.numeric_column('age')\n",
    "education_num=tf.feature_column.numeric_column('education_num')\n",
    "#capital_gain=tf.feature_column.numeric_column('capital_gain')\n",
    "#capital_loss=tf.feature_column.numeric_column('capital_loss')\n",
    "hour_per_week=tf.feature_column.numeric_column('hours_per_week')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### put all these variable into a single list with the variable name feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols=[gender,occupation,matrial_status,relationship,education,workclass,native_country,\n",
    "            age,education_num,hour_per_week]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Input function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch_size is up to you but do make sure to shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func=tf.estimator.inputs.pandas_input_fn(x=x_train,y=y_train,\n",
    "                                              batch_size=10,\n",
    "                                              num_epochs=1000,\n",
    "                                              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your model with tf.estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a linearClassifier(if you want to use a DNNClassifier keep in mind you will need to create embedded columns out of the cateogrical feature that use string check out the previous lecture on this for more info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\satya\\AppData\\Local\\Temp\\tmpuwopxq_e\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\satya\\\\AppData\\\\Local\\\\Temp\\\\tmpuwopxq_e', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001D1FE4F3B08>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model=tf.estimator.LinearClassifier(feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train your model on the data for atleast 5000 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\satya\\AppData\\Local\\Temp\\tmpuwopxq_e\\model.ckpt.\n",
      "INFO:tensorflow:loss = 6.931472, step = 1\n",
      "INFO:tensorflow:global_step/sec: 51.3854\n",
      "INFO:tensorflow:loss = 4.3280193e-05, step = 101 (2.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.3125\n",
      "INFO:tensorflow:loss = 4.782111e-05, step = 201 (0.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.782\n",
      "INFO:tensorflow:loss = 2.6100404e-06, step = 301 (0.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.596\n",
      "INFO:tensorflow:loss = 2.5253956e-07, step = 401 (0.754 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.314\n",
      "INFO:tensorflow:loss = 4.369076e-06, step = 501 (0.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.294\n",
      "INFO:tensorflow:loss = 1.9949218e-07, step = 601 (0.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.135\n",
      "INFO:tensorflow:loss = 1.2612165e-07, step = 701 (0.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.311\n",
      "INFO:tensorflow:loss = 1.6773516e-05, step = 801 (0.767 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.033\n",
      "INFO:tensorflow:loss = 5.5194128e-06, step = 901 (0.735 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.687\n",
      "INFO:tensorflow:loss = 3.5680252e-05, step = 1001 (0.744 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.877\n",
      "INFO:tensorflow:loss = 2.7589223e-07, step = 1101 (0.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.54\n",
      "INFO:tensorflow:loss = 3.1214267e-07, step = 1201 (0.743 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.23\n",
      "INFO:tensorflow:loss = 9.069393e-07, step = 1301 (0.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.785\n",
      "INFO:tensorflow:loss = 1.3123322e-05, step = 1401 (0.852 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.565\n",
      "INFO:tensorflow:loss = 1.235313e-07, step = 1501 (0.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.516\n",
      "INFO:tensorflow:loss = 4.7483204e-06, step = 1601 (0.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.629\n",
      "INFO:tensorflow:loss = 1.065833e-06, step = 1701 (0.784 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.135\n",
      "INFO:tensorflow:loss = 1.2474557e-06, step = 1801 (0.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.943\n",
      "INFO:tensorflow:loss = 6.937192e-08, step = 1901 (0.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 126.716\n",
      "INFO:tensorflow:loss = 0.00021413302, step = 2001 (0.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.023\n",
      "INFO:tensorflow:loss = 2.9049888e-06, step = 2101 (0.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.531\n",
      "INFO:tensorflow:loss = 1.7052392e-06, step = 2201 (0.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.29\n",
      "INFO:tensorflow:loss = 8.335083e-06, step = 2301 (0.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.5\n",
      "INFO:tensorflow:loss = 5.397835e-07, step = 2401 (0.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 126.753\n",
      "INFO:tensorflow:loss = 7.750642e-05, step = 2501 (0.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.651\n",
      "INFO:tensorflow:loss = 8.645842e-07, step = 2601 (0.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.633\n",
      "INFO:tensorflow:loss = 0.00020615173, step = 2701 (0.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.684\n",
      "INFO:tensorflow:loss = 1.5428975e-07, step = 2801 (0.754 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.383\n",
      "INFO:tensorflow:loss = 1.2005557e-07, step = 2901 (0.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.324\n",
      "INFO:tensorflow:loss = 2.4622295e-05, step = 3001 (0.879 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.499\n",
      "INFO:tensorflow:loss = 0.00029797948, step = 3101 (0.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.558\n",
      "INFO:tensorflow:loss = 4.5521334e-05, step = 3201 (0.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.407\n",
      "INFO:tensorflow:loss = 1.3857549e-05, step = 3301 (0.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.747\n",
      "INFO:tensorflow:loss = 6.582773e-06, step = 3401 (0.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.41\n",
      "INFO:tensorflow:loss = 2.1005187e-07, step = 3501 (0.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.477\n",
      "INFO:tensorflow:loss = 1.5879836e-08, step = 3601 (0.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 127.141\n",
      "INFO:tensorflow:loss = 9.1624065e-07, step = 3701 (0.787 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.961\n",
      "INFO:tensorflow:loss = 6.377274e-05, step = 3801 (0.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.854\n",
      "INFO:tensorflow:loss = 2.403285e-05, step = 3901 (0.756 sec)\n",
      "INFO:tensorflow:global_step/sec: 127.464\n",
      "INFO:tensorflow:loss = 2.2110444e-07, step = 4001 (0.785 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.175\n",
      "INFO:tensorflow:loss = 6.6818347e-06, step = 4101 (0.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.122\n",
      "INFO:tensorflow:loss = 2.0104098e-05, step = 4201 (0.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.6\n",
      "INFO:tensorflow:loss = 1.2767002e-07, step = 4301 (0.753 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.379\n",
      "INFO:tensorflow:loss = 1.4013496e-06, step = 4401 (0.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.849\n",
      "INFO:tensorflow:loss = 1.869327e-06, step = 4501 (0.764 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.198\n",
      "INFO:tensorflow:loss = 2.7947015e-06, step = 4601 (0.768 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.373\n",
      "INFO:tensorflow:loss = 1.28902e-05, step = 4701 (0.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.907\n",
      "INFO:tensorflow:loss = 8.024164e-06, step = 4801 (0.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.465\n",
      "INFO:tensorflow:loss = 2.3504035e-07, step = 4901 (0.731 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into C:\\Users\\satya\\AppData\\Local\\Temp\\tmpuwopxq_e\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6.2239575e-05.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearClassifier at 0x1d1fe4f35c8>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=input_func,steps=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create aprediction input function Remember to only support x_test data and keep shuffle=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_fn=tf.estimator.inputs.pandas_input_fn(x=x_test,batch_size=len(x_test),shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use model.predict() and pass in your input function.this will produce a generator of predictions which you can then transform into a list,with list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gn=model.predict(input_fn=pred_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\satya\\AppData\\Local\\Temp\\tmpuwopxq_e\\model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "predictions=list(pred_gn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds=[pred['class_ids'][0] for pred in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each item in your list will look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of only the class_ids key value from the prediction list of dictionaries these are the predictions you will use to compare against the real y_test values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import classification report from sklearn.metrics and then see if you can figure out how to use it to easily get a full report of your model's performance on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00      9049\n",
      "\n",
      "    accuracy                           1.00      9049\n",
      "   macro avg       1.00      1.00      1.00      9049\n",
      "weighted avg       1.00      1.00      1.00      9049\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,final_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
